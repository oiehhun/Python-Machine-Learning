{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3장 평가(Evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모델의 성능을 평가하는 지표 : `분류모델`인가, `회귀모델`인가에 따라 달라진다.\n",
    "\n",
    " + 회귀 : 오차(실제값 - 예측값)를 이용한 성능 평가 (교재 5장에서 공부)\n",
    " + 분류 : 3장에서 공부\n",
    "   - 정확도 (accuracy)\n",
    "   - 혼동행렬 (오차 행렬, confusion matrix)\n",
    "   - 정밀도 (precision)\n",
    "   - 재현율 (recall)\n",
    "   - F1 score\n",
    "   - ROC, AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1 Accuracy(정확도)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 정확도 = $ \\frac {실제값과 예측값이 일치하는 데이터의 수} {전체 데이터의 수} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도는 모델의 성능을 언제나 '정확하게' 평가할까? 아래 예를 보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "교재 150쪽 : \n",
    "\n",
    "100개의 데이터가 있는데 그중 90개의 label은 0이고 10개의 label은 1이다. 무조건 0으로 분류하는 분류법의 정확도는 얼마인가?\n",
    "\n",
    "    답) 90%!\n",
    "\n",
    "머신러닝 알고리즘이라고 부를 수도 없는 분류법의 정확도가 무려 90%다. 왜 이런 문제가 생길까? \n",
    "\n",
    "`데이터에 있는 label의 분포가 한쪽으로 치우쳐있기 때문(unbalanced data)이다.` 타이타닉 데이터로도 이런 문제점을 확인할 수 있다. 타이타닉 데이터에서 성별('Sex') 변수는 여성이면 0, 남성이면 1값을 갖는다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2장에서 titanic `데이터의 전처리`를 위해 만든 함수 **transform_features()**를 그대로 이용하자. (교재 p.140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
    "    df['Cabin'].fillna('N',inplace=True)\n",
    "    df['Embarked'].fillna('N',inplace=True)\n",
    "    df['Fare'].fillna(0,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행. \n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin','Sex','Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 Data Preprocessing 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2장과 마찬가지 방법으로 타이타닉 데이터를 train, test 데이터로 나누자. X에는 feature 변수들, y에는 target 변수가 들어있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = pd.read_csv('./titanic_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.00</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.00</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                      Name  \\\n",
       "886          887         0       2                     Montvila, Rev. Juozas   \n",
       "887          888         1       1              Graham, Miss. Margaret Edith   \n",
       "888          889         0       3  Johnston, Miss. Catherine Helen \"Carrie\"   \n",
       "889          890         1       1                     Behr, Mr. Karl Howell   \n",
       "890          891         0       3                       Dooley, Mr. Patrick   \n",
       "\n",
       "        Sex   Age  SibSp  Parch      Ticket   Fare Cabin Embarked  \n",
       "886    male  27.0      0      0      211536  13.00   NaN        S  \n",
       "887  female  19.0      0      0      112053  30.00   B42        S  \n",
       "888  female   NaN      1      2  W./C. 6607  23.45   NaN        S  \n",
       "889    male  26.0      0      0      111369  30.00  C148        C  \n",
       "890    male  32.0      0      0      370376   7.75   NaN        Q  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> (891, 12)\n"
     ]
    }
   ],
   "source": [
    "print(type(titanic_df), titanic_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                               Name  \\\n",
       "0              1       3                            Braund, Mr. Owen Harris   \n",
       "1              2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2              3       3                             Heikkinen, Miss. Laina   \n",
       "3              4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4              5       3                           Allen, Mr. William Henry   \n",
       "..           ...     ...                                                ...   \n",
       "886          887       2                              Montvila, Rev. Juozas   \n",
       "887          888       1                       Graham, Miss. Margaret Edith   \n",
       "888          889       3           Johnston, Miss. Catherine Helen \"Carrie\"   \n",
       "889          890       1                              Behr, Mr. Karl Howell   \n",
       "890          891       3                                Dooley, Mr. Patrick   \n",
       "\n",
       "        Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0      male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1    female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
       "2    female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3    female  35.0      1      0            113803  53.1000  C123        S  \n",
       "4      male  35.0      0      0            373450   8.0500   NaN        S  \n",
       "..      ...   ...    ...    ...               ...      ...   ...      ...  \n",
       "886    male  27.0      0      0            211536  13.0000   NaN        S  \n",
       "887  female  19.0      0      0            112053  30.0000   B42        S  \n",
       "888  female   NaN      1      2        W./C. 6607  23.4500   NaN        S  \n",
       "889    male  26.0      0      0            111369  30.0000  C148        C  \n",
       "890    male  32.0      0      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df= titanic_df.drop('Survived', axis = 1)\n",
    "X_titanic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_titanic_df = transform_features(X_titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> (712, 8)\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train), X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> (179, 8)\n"
     ]
    }
   ],
   "source": [
    "print(type(X_test), X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'> (712,)\n"
     ]
    }
   ],
   "source": [
    "print(type(y_train), y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'> (179,)\n"
     ]
    }
   ],
   "source": [
    "print(type(y_test), y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원래 titanic_df에는 891개 데이터가 있었는데 train 712개, test 179 개로 (80 : 20 비율로) 나누었다. 그리고 원래 12개의 변수가 있었지만 분석에 불필요한 세 변수('Passengerld', 'Name', \"Ticket')는 제외하고 9개만 남겼다. 9개 중에서 'Survived' 변수는 target변수가 되고 나머지 8개 변수가 feature 변수가 되어 X_train, X_test에 들어있다. 8개 변수의 이름은 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0042</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0125</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex        Age  SibSp  Parch     Fare  Cabin  Embarked\n",
       "140       3    0  29.699118      0      2  15.2458      7         0\n",
       "439       2    1  31.000000      0      0  10.5000      7         3\n",
       "817       2    1  31.000000      1      1  37.0042      7         0\n",
       "378       3    1  20.000000      0      0   4.0125      7         0\n",
       "491       3    1  21.000000      0      0   7.2500      7         3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LavelEncoder()를 이용한 인코딩을 거쳐 모든 변수가 숫자값을 갖게 된 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "퀴즈 : Age 변수의 값 가운데 29.699118라는 값이 보인다. 나이값으로는 이상하다. 어찌 된걸까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "나이의 결측값 대체를 나이의 평균으로 했기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId                              141\n",
       "Survived                                   0\n",
       "Pclass                                     3\n",
       "Name           Boulos, Mrs. Joseph (Sultana)\n",
       "Sex                                   female\n",
       "Age                                      NaN\n",
       "SibSp                                      0\n",
       "Parch                                      2\n",
       "Ticket                                  2678\n",
       "Fare                                 15.2458\n",
       "Cabin                                    NaN\n",
       "Embarked                                   C\n",
       "Name: 140, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.iloc[140]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "판다스의 **pd.crosstab()** 함수를 이용해서 성별 생존자-사망자 분류표를 만들어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Sex</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81</td>\n",
       "      <td>468</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>233</td>\n",
       "      <td>109</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>314</td>\n",
       "      <td>577</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Sex       female  male  All\n",
       "Survived                   \n",
       "0             81   468  549\n",
       "1            233   109  342\n",
       "All          314   577  891"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(titanic_df['Survived'], titanic_df['Sex'], margins = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 생존률은 \n",
    "\n",
    "$$342/891 = 38\\%$$ \n",
    "\n",
    "인데 성별로 나누어서 보면 여성(Sex = 0) 생존률은 \n",
    "\n",
    "$$233/314 = 74\\%,$$ \n",
    "\n",
    "남성(Sex = 1) 생존률은 $$109/577= 19\\%. $$\n",
    "\n",
    "성별이 1이면 사망, 0이면 생존으로 분류한다고 해보자. 정확도는 얼마일까? 남성 사망자(468명)과 여성 생존자(233명)을 정확하게 분류하게 되므로 정확도는 다음과 같다.\n",
    "\n",
    "$$ \\frac {233 + 468} {891} = 78.7 \\% . $$\n",
    "\n",
    "정확도가 꽤 높다! 그렇다면 다른 변수는 다 무시하고 오로지 성별만으로 생존여부를 예측하는 이 방법이 좋은 분류법이라고 할 수 있을까?\n",
    "\n",
    "좋지 않다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 설명을 코드로 만들어보자. 아래 `MyDummyClassifier()` 클래스는 단순히 `BaseEstimator` 클래스를 상속받아 만든다. 여기서 `BaseEstimator` 클래스는 머신러닝 개발자들이 사이킷런으로 나름의 추정방법(Estimator)를 만드는 과정을 간편하게 해주는 기본 클래스로서 `from sklearn.base import BaseEstimator`와 같이 불러쓰면 된다.\n",
    "\n",
    "`MyDummyClassifier()` 클래스에도 다른 분류기들처럼 `fit, predict`가 정의되어 있는데 `fit()`은 데이터로부터 아무 것도 학습하지 않는다. 그리고 `predict()`는 성별만 보고 값이 1(남성)이면 무조건 사망, 여성(0)이면 무조건 생존으로 분류한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "   \n",
    "    def fit(self, X, y = None):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        pred = np.zeros((X.shape[0], 1))\n",
    "        for i in range (X.shape[0]):\n",
    "            if X['Sex'].iloc[i] == 1:\n",
    "                pred[i] = 0\n",
    "            else :\n",
    "                pred[i] = 1\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 생성한 MyDummyClassifier를 이용하여 학습, 예측, 평가를 수행해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier의 정확도는: 0.7877\n"
     ]
    }
   ],
   "source": [
    "myclf = MyDummyClassifier()\n",
    "myclf.fit(X_train, y_train)\n",
    "mypredictions = myclf.predict(X_test)\n",
    "print('Dummy Classifier의 정확도는: {0:.4f}'.format(accuracy_score(y_test , mypredictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 데이터에서도 우리가 전체 데이터에서 계산한 정확도(0.78)과 거의 비슷한 값이 나왔다. 순 엉터리 분류방법인데도 역시 상당히 높은 값이 나왔다.\n",
    "\n",
    "즉, `정확도라는 지표는 분류 알고리즘의 성능을 판단하는 기준으로 부적절할 수 있다.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다른 데이터를 가지고 정확도의 한계에 대해 더 살펴보자. \n",
    "\n",
    "예제로 이용할 유명한 [**MNIST 데이터베이스**](https://en.wikipedia.org/wiki/MNIST_database) (Modified National Institute of Standards and Technology database)는 사람들이 손으로 쓴 0부터 9까지 열 개 숫자 글씨를 이미지 파일로 만든 것이다. 이 데이터는 이미지를 판독하는 머신러닝의 성능을 알아볼 때 널리 쓰인다. [사이킷런의 설명](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits)을 잠시 보자. \n",
    "\n",
    "교재에서 이용할 데이터는 `from sklearn.datasets import load_digits`와 같이 불러올 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "type(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "print(digits.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n",
      "### digits.data.shape: (1797, 64)\n"
     ]
    }
   ],
   "source": [
    "print(digits.data)\n",
    "print(\"### digits.data.shape:\", digits.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1797개 feature 데이터 가운데 가장 앞에 있는 것을 살펴보자. 64개의 값으로 이루어져 있는데 $ 8 \\times 8$ pixel의 강도를 0부터 15까지의 숫자로 나타낸 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 데이터를 아래와 같이 그림으로 나타내보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAECCAYAAADXWsr9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAL40lEQVR4nO3dW4hd9RXH8d+vY7xGSaxWJBHtSAmIUHNBKgFpNYpWsS81RFCotCQPrRha0NiX4ptPYh+KELxU8IajBoq01gQVEVrtTIz1MrFoiJhEHSWRGAsR4+rD2SkxnTp7xv3/z5mzvh845MzMmb3WzOR39t7n7L2XI0IABtu3ZrsBAOURdCABgg4kQNCBBAg6kABBBxLoi6DbvsL2W7bftr2hcK37bE/Yfr1knSPqnWX7Odvjtt+wfXPhesfbftn2q02920vWa2oO2X7F9lOlazX1dtp+zfY226OFay2w/bjt7c3f8KKCtZY0P9Ph237b6ztZeETM6k3SkKR3JA1LOlbSq5LOK1jvYknLJL1e6ec7U9Ky5v7Jkv5V+OezpPnN/XmSXpL0g8I/468lPSzpqUq/052STqtU6wFJv2juHytpQaW6Q5I+kHR2F8vrhzX6hZLejogdEfG5pEcl/aRUsYh4QdLeUsufpN77EbG1uf+ppHFJiwrWi4g40Hw4r7kVOyrK9mJJV0m6p1SN2WL7FPVWDPdKUkR8HhGfVCp/qaR3IuLdLhbWD0FfJOm9Iz7epYJBmE22z5G0VL21bMk6Q7a3SZqQtDkiSta7S9Itkr4sWONoIekZ22O21xasMyzpI0n3N7sm99g+qWC9I62R9EhXC+uHoHuSzw3ccbm250t6QtL6iNhfslZEHIqICyQtlnSh7fNL1LF9taSJiBgrsfyvsTIilkm6UtIvbV9cqM4x6u3m3R0RSyV9Jqnoa0iSZPtYSddIGulqmf0Q9F2Szjri48WS9sxSL0XYnqdeyB+KiCdr1W02M5+XdEWhEislXWN7p3q7XJfYfrBQrf+KiD3NvxOSNqm3+1fCLkm7jtgiely94Jd2paStEfFhVwvsh6D/Q9L3bH+3eSZbI+lPs9xTZ2xbvX288Yi4s0K9020vaO6fIGmVpO0lakXEbRGxOCLOUe/v9mxEXF+i1mG2T7J98uH7ki6XVOQdlIj4QNJ7tpc0n7pU0pslah3lOnW42S71Nk1mVUR8YftXkv6q3iuN90XEG6Xq2X5E0g8lnWZ7l6TfRcS9peqpt9a7QdJrzX6zJP02Iv5cqN6Zkh6wPaTeE/ljEVHlba9KzpC0qff8qWMkPRwRTxesd5Okh5qV0A5JNxasJdsnSrpM0rpOl9u8lA9ggPXDpjuAwgg6kABBBxIg6EACBB1IoK+CXvhwxlmrRT3qzXa9vgq6pJq/zKp/OOpRbzbr9VvQARRQ5IAZ2wN9FM7ChQun/T0HDx7UcccdN6N6ixZN/2S+vXv36tRTT51Rvf37p3/OzYEDBzR//vwZ1du9e/e0vyci1BwdN22HDh2a0ffNFRHxP7+YWT8Edi5atWpV1Xp33HFH1XpbtmypWm/DhuInhH3Fvn37qtbrB2y6AwkQdCABgg4kQNCBBAg6kABBBxIg6EACBB1IoFXQa45MAtC9KYPeXGTwD+pdgvY8SdfZPq90YwC602aNXnVkEoDutQl6mpFJwKBqc1JLq5FJzYnytc/ZBdBCm6C3GpkUERslbZQG/zRVYK5ps+k+0COTgAymXKPXHpkEoHutLjzRzAkrNSsMQGEcGQckQNCBBAg6kABBBxIg6EACBB1IgKADCRB0IAEmtcxA7ckpw8PDVevNZOTUN7F3796q9VavXl213sjISNV6k2GNDiRA0IEECDqQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJEDQgQTajGS6z/aE7ddrNASge23W6H+UdEXhPgAUNGXQI+IFSXXPOgDQKfbRgQQ6O02V2WtA/+os6MxeA/oXm+5AAm3eXntE0t8kLbG9y/bPy7cFoEtthixeV6MRAOWw6Q4kQNCBBAg6kABBBxIg6EACBB1IgKADCRB0IIGBmL22fPnyqvVqz0I799xzq9bbsWNH1XqbN2+uWq/2/xdmrwGogqADCRB0IAGCDiRA0IEECDqQAEEHEiDoQAIEHUiAoAMJtLk45Fm2n7M9bvsN2zfXaAxAd9oc6/6FpN9ExFbbJ0sas705It4s3BuAjrSZvfZ+RGxt7n8qaVzSotKNAejOtPbRbZ8jaamkl4p0A6CI1qep2p4v6QlJ6yNi/yRfZ/Ya0KdaBd32PPVC/lBEPDnZY5i9BvSvNq+6W9K9ksYj4s7yLQHoWpt99JWSbpB0ie1tze3HhfsC0KE2s9delOQKvQAohCPjgAQIOpAAQQcSIOhAAgQdSICgAwkQdCABgg4kMBCz1xYuXFi13tjYWNV6tWeh1Vb795kRa3QgAYIOJEDQgQQIOpAAQQcSIOhAAgQdSICgAwkQdCABgg4k0OYqsMfbftn2q83stdtrNAagO22OdT8o6ZKIONBc3/1F23+JiL8X7g1AR9pcBTYkHWg+nNfcGNAAzCGt9tFtD9neJmlC0uaIYPYaMIe0CnpEHIqICyQtlnSh7fOPfozttbZHbY923COAb2har7pHxCeSnpd0xSRf2xgRKyJiRTetAehKm1fdT7e9oLl/gqRVkrYX7gtAh9q86n6mpAdsD6n3xPBYRDxVti0AXWrzqvs/JS2t0AuAQjgyDkiAoAMJEHQgAYIOJEDQgQQIOpAAQQcSIOhAAsxem4EtW7ZUrTfoav/99u3bV7VeP2CNDiRA0IEECDqQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJEDQgQRaB70Z4vCKbS4MCcwx01mj3yxpvFQjAMppO5JpsaSrJN1Tth0AJbRdo98l6RZJX5ZrBUApbSa1XC1pIiLGpngcs9eAPtVmjb5S0jW2d0p6VNIlth88+kHMXgP615RBj4jbImJxRJwjaY2kZyPi+uKdAegM76MDCUzrUlIR8bx6Y5MBzCGs0YEECDqQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJDAQs9dqz9Javnx51Xq11Z6FVvv3OTIyUrVeP2CNDiRA0IEECDqQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJEDQgQRaHQLbXOr5U0mHJH3BJZ2BuWU6x7r/KCI+LtYJgGLYdAcSaBv0kPSM7THba0s2BKB7bTfdV0bEHtvfkbTZ9vaIeOHIBzRPADwJAH2o1Ro9IvY0/05I2iTpwkkew+w1oE+1maZ6ku2TD9+XdLmk10s3BqA7bTbdz5C0yfbhxz8cEU8X7QpAp6YMekTskPT9Cr0AKIS314AECDqQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJOCI6H6hdvcL/RrDw8M1y2l0dLRqvXXr1lWtd+2111atV/vvt2LFYJ+OERE++nOs0YEECDqQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJEDQgQQIOpBAq6DbXmD7cdvbbY/bvqh0YwC603aAw+8lPR0RP7V9rKQTC/YEoGNTBt32KZIulvQzSYqIzyV9XrYtAF1qs+k+LOkjSffbfsX2Pc0gh6+wvdb2qO26p3YBmFKboB8jaZmkuyNiqaTPJG04+kGMZAL6V5ug75K0KyJeaj5+XL3gA5gjpgx6RHwg6T3bS5pPXSrpzaJdAehU21fdb5L0UPOK+w5JN5ZrCUDXWgU9IrZJYt8bmKM4Mg5IgKADCRB0IAGCDiRA0IEECDqQAEEHEiDoQAIDMXuttrVr11atd+utt1atNzY2VrXe6tWrq9YbdMxeA5Ii6EACBB1IgKADCRB0IAGCDiRA0IEECDqQAEEHEpgy6LaX2N52xG2/7fUVegPQkSmvGRcRb0m6QJJsD0naLWlT2bYAdGm6m+6XSnonIt4t0QyAMqYb9DWSHinRCIByWge9uab7NZJG/s/Xmb0G9Km2Axwk6UpJWyPiw8m+GBEbJW2UBv80VWCumc6m+3Visx2Yk1oF3faJki6T9GTZdgCU0HYk078lfbtwLwAK4cg4IAGCDiRA0IEECDqQAEEHEiDoQAIEHUiAoAMJEHQggVKz1z6SNJNz1k+T9HHH7fRDLepRr1a9syPi9KM/WSToM2V7NCJWDFot6lFvtuux6Q4kQNCBBPot6BsHtBb1qDer9fpqHx1AGf22RgdQAEEHEiDoQAIEHUiAoAMJ/AchD47vy2xCkAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.gray() \n",
    "plt.matshow(digits.images[0]) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또 100, 1700번째 숫자의 이미지를 그린 아래 그림들을 보라. 각각 어떤 숫자 같은가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.gray() \n",
    "plt.matshow(digits.images[100]) \n",
    "plt.matshow(digits.images[1700]) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target 값들도 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 ... 8 9 8]\n",
      "### digits.target.shape: (1797,)\n"
     ]
    }
   ],
   "source": [
    "print(digits.target)\n",
    "print(\"### digits.target.shape:\", digits.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "즉 맨 첫번째 숫자는 0이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100번, 1700번 숫자는 4, 5다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 5\n"
     ]
    }
   ],
   "source": [
    "print(digits.target[100], digits.target[1700])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 데이터는 이 정도 살펴보고 교재의 설명으로 돌아가자.\n",
    "\n",
    "원래 이 데이터에서 target은 10개의 범주를 갖지만(즉 다중 분류 방법을 써서 분류해야할 데이터이지만) 교재의 아래 코드에서는 문제를 `이진 분류`(binary classification)로 간단하게 만들기 위해 숫자가 7인가 아닌가라는 두 범주만 갖는 경우를 다룬다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    # 입력값으로 들어오는 X 데이터 셋의 크기만큼 모두 0값으로 만들어서 반환\n",
    "    def predict(self, X):\n",
    "        return np.zeros( (len(X), 1) , dtype = bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 `MyFakeClassifier()` 클래스 안에서 정의한 predict() 함수를 보자. 그 위에 있는 fit() 함수가 아무런 훈련도 하지 않은 엉터리 모형을 만들기 때문에 predict() 함수 역시 그냥 모든 target 데이터를 무조건 0으로 예측 분류한다. 그래서 아예 클래스 이름도 '가짜 fake'라고 지었다. 그런 엉터리 방법이 숫자 데이터를 얼마나 정확하게 분류할 수 있을까?\n",
    "\n",
    "이 경우 역시 알고리즘 자체의 성능이 아니라 데이터의 분포가 알고리즘의 정확도를 결정한다. 이유를 알아보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target == 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0부터 9사이의 숫자들이 골고루 들어있다면 그 중에 7은 1/10이고 y값의 비는 9:1 정도일 것이다. 즉 이 데이터는 매우 불균형한 데이터라고 할 수 있다. 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1618,  179], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(digits.target == 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "즉 우리가 예상한 대로 전체 1797개 데이터 중에서 7은 약 10%에 해당하는 179개 뿐이고 나머지는 다른 숫자들이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 `(digits.target == 7)` 변수는 digits 숫자 값이 7인지 아닌지를 나타내는 `(즉 True, False값을 갖는)` **bool data**이다. 이 변수를 아래와 같이 1, 0이라는 정수값을 갖는 y 변수로 바꾼 다음 digits.data와 y를 train과 test data로 나누자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = (digits.target == 7).astype(int)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (digits.target == 7).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split( digits.data, y, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래에서 확인할 수 있듯 test data에서도 역시 0과 1의 비는 405 : 45 (즉, 9 :1)로서 매우 치우쳐있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 테스트 세트 크기 : (450,)\n",
      "테스트 세트 레이블 0 과 1의 분포도\n",
      "0    405\n",
      "1     45\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 불균형한 레이블 데이터 분포도 확인. \n",
    "print('레이블 테스트 세트 크기 :', y_test.shape)\n",
    "print('테스트 세트 레이블 0 과 1의 분포도')\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 test data를 가지고 실제 y 값과 예측값(fakepred)이 얼마나 일치하는지 정확도를 구해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "fakeclf = MyFakeClassifier()\n",
    "fakeclf.fit(X_train, y_train)\n",
    "fakepred = fakeclf.predict(X_test)\n",
    "print(accuracy_score(y_test , fakepred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "무조건 모든 예측을 0으로 해버려도 test data에서의 분류 정확도가 무려 90%나 된다! 그러므로 `불균형데이터를 분류할 때에는 정확도를 성능 지표로 써서는 역시 안 되겠다.`\n",
    "\n",
    "그러므로 다른 평가 지표들을 살펴보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 여기서 수업자료(\"참고 : 혼동행렬 (오차행렬, confusion matrix)과 머신러닝 모델의 성능 평가\")를 보고 다음으로 넘어가자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도, 혼동행렬, 정밀도, 재현율, F1 점수 등의 평가 지표값들은 사이킷런에서 sklearm.metrics 안에 들어있는 다음 함수들을 불러와서 구할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- confusion_matrix\n",
    "- accuracy_score\n",
    "- precion_score\n",
    "- recall_score\n",
    "- f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 혼동행렬 (Confusion Matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "교재 153쪽의 그림을 보자. 설명은 기본적으로 이진 분류에 대한 것이다. 암을 예측하는 검사방법이 있다고 하자. 실제 상황은 암이 있거나(양성) 없다(음성). 예측 결과 역시 양성, 음성인데 잘못된 예측을 할 수도 있다.\n",
    "\n",
    "* TN(true negative) – 음성을 올바르게 예측한 것, 진음성\n",
    "* TP(true positive) – 양성을 올바르게 예측한 것, 진양성\n",
    "* FP(false positive) – 음성을 양성으로 잘못 예측한 것, 위양성\n",
    "* FN(false negative) – 양성을 음성으로 잘못 예측한 것, 위음성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 네 가지 결과를 $ 2 \\times 2 $ 행렬 모양으로 나타낸 것을 혼동행렬(오차행렬, confusion matrix)라고 한다.\n",
    "\n",
    "사이킷런에서는 아래와 같이 혼동행렬(오차행렬)을 만들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[405,   0],\n",
       "       [ 45,   0]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test , fakepred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오차행렬은 2차원 넘파이 배열 형태로 출력된다. y 값이 0이면 음성, 1이면 양성이라고 부르자. 위의 결과에 따르면 \n",
    "\n",
    "    TN = 405, TP = 0, FP = 0, FN = 45\n",
    "\n",
    "임을 알 수 있다(155쪽 그림을 보라)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 양성(7이라는 숫자)이 45개 있지만 모두 음성으로 잘못 분류했다. 결국 양성을 하나도 찾아내지 못했는데도 정확도는 405/450 = 90%가 되었다. 이유는 양성은 적은 반면 음성 데이터가 워낙 많기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**퀴즈**\n",
    "\n",
    "코로나 검사 대상자들 가운데 양성은 1%라고 해보자. 모든 사람에게 음성 판정을 내리는 검사법의 정확도는 얼마인가? 99%\n",
    "\n",
    "현실적으로 그런 검사법이 쓸모가 있겠는가? NO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 정밀도(Precision)와 재현율(Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** MyFakeClassifier의 예측 결과로 정밀도와 재현율 측정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정밀도: 0.0\n",
      "재현율: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score , recall_score\n",
    "\n",
    "print(\"정밀도:\", precision_score(y_test, fakepred))\n",
    "print(\"재현율:\", recall_score(y_test, fakepred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 방법의 정확도은 90%였다. 하지만 양성을 전혀 찾아내지 못했기 때문에 정밀도와 재현율은 0이다(TN=405, TP=0, FP=0, FN=45)이므로 사실 재현율은 0/45이지만 정밀도는 0/0이다.(말도 안되는 경우인 것이다)!\n",
    "\n",
    "편리하게 분석하기 위해 오차행렬, 정확도, 정밀도, 재현율을 한꺼번에 계산하는 함수를 만들어 놓고 타이타닉 데이터를 분류해보자. 교재에서 예로 들고 있는 분류 알고리즘은 로지스틱회귀 방법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 오차행렬, 정확도, 정밀도, 재현율을 한꺼번에 계산하는 함수 생성 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score , recall_score , confusion_matrix\n",
    "\n",
    "def get_clf_eval(y_test , pred):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}'.format(accuracy , precision ,recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 원본 데이터를 재로딩, 데이터 가공, 학습데이터/테스트 데이터 분할. \n",
    "titanic_df = pd.read_csv('./titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df= titanic_df.drop('Survived', axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, \\\n",
    "                                                    test_size=0.20, random_state=11)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "lr_clf.fit(X_train , y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "get_clf_eval(y_test , pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 오차행렬을 가지고 정확도, 정밀도, 재현율 계산을 해보고 출력결과와 비교해보라."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision/Recall Trade-off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정밀도와 재현율은 상호보완적이므로 동시에 높일 수 없다. 이유는?\n",
    "\n",
    "암 검사에서 대부분 양성으로 판정하는 검사법이 있다면 암이 있는 사람은 거의 양성 판정을 받을 것이므로 FN 낮아져 재현율은 높아질 것이다. 하지만 암이 없는 사람 중에 양성 판정을 받는 사람 (위양성)FP이 높아져 정밀도는 낮아질 것이다.\n",
    "\n",
    "또 대부분을 음성으로 판정하는 검사법이 있다면 많은 실제 암환자를 놓피게 되므로 재현율은 낮아지는 반면 위양성(FP)가 줄어들어 정밀도는 높아질 것이다.\n",
    "\n",
    "이와 관련해서 target 변수 클래스의 예측확률에 대해 알아보자. 역시 `로지스틱회귀 방법으로 타이타닉 데이터를 분류`한다.\n",
    "\n",
    "사이킷런에서는 각 데이터에 대해 분류 클래스별 **predict_proba()**를 계산하여 그 값이 큰 클래스로 분류한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_proba()결과 Shape : (179, 2)\n",
      "pred_proba array에서 앞 3개만 샘플로 추출 \n",
      ": [[0.46162417 0.53837583]\n",
      " [0.87858538 0.12141462]\n",
      " [0.87723741 0.12276259]]\n",
      "두개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \n",
      " [[0.46162417 0.53837583 1.        ]\n",
      " [0.87858538 0.12141462 0.        ]\n",
      " [0.87723741 0.12276259 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "pred  = lr_clf.predict(X_test)\n",
    "print('pred_proba()결과 Shape : {0}'.format(pred_proba.shape))\n",
    "print('pred_proba array에서 앞 3개만 샘플로 추출 \\n:', pred_proba[:3])\n",
    "\n",
    "# 예측 확률 array 와 예측 결과값 array 를 concatenate 하여 예측 확률과 결과값을 한눈에 확인\n",
    "pred_proba_result = np.concatenate([pred_proba , pred.reshape(-1,1)],axis=1)\n",
    "print('두개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \\n',pred_proba_result[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 출력을 보면 첫 세 개 데이터가 왜 1,0,0으로 분류되었는지 알 수 있다. 사이킷런은 클래스별 예측확률을 구한 다음 그 확률이 0.5보다 큰 클래스로 데이터를 분류한다. 기준이 꼭 0.5이여야할 이유는? 없다. 교재 161쪽에서 소개하는 **Binarizer** 클래스를 이용하여 우리가 원하는 값으로 바꾸어보자. Binarizer 는 sklearn.preprocessing 안에 들어있는 클래스다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binarizer 활용**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 클래스는 아래 코드에서 보듯 `2차원 배열을 입력받아 threshold(임계값)보다 크면 1, 아니면 0값을 반환`한다. 그 과정은 **fit()** 과 **transform()** 또는 둘을 합친 **fit_transform()** 메서드를 이용해서 진행된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "X = [[ 1, -1,  2],\n",
    "     [ 2,  0,  0],\n",
    "     [ 0,  1.1, 1.2]]\n",
    "\n",
    "# threshold 기준값보다 같거나 작으면 0을, 크면 1을 반환\n",
    "binarizer = Binarizer(threshold = 1.1)                     \n",
    "print(binarizer.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**분류 결정 임계값 0.5 기반에서 Binarizer를 이용하여 예측값 변환**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "#Binarizer의 threshold 설정값. 분류 결정 임곗값임.  \n",
    "custom_threshold = 0.5\n",
    "\n",
    "# predict_proba( ) 반환값의 두번째 컬럼 , 즉 Positive 클래스 컬럼 하나만 추출하여 Binarizer를 적용\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1) \n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**분류 결정 임계값 0.4 기반에서 Binarizer를 이용하여 예측값 변환**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[99 19]\n",
      " [10 51]]\n",
      "정확도: 0.8380, 정밀도: 0.7286, 재현율: 0.8361\n"
     ]
    }
   ],
   "source": [
    "# Binarizer의 threshold 설정값을 0.4로 설정. 즉 분류 결정 임곗값을 0.5에서 0.4로 낮춤  \n",
    "custom_threshold = 0.4\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1) \n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test , custom_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**여러개의 분류 결정 임곗값을 변경하면서  Binarizer를 이용하여 예측값 변환**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임곗값: 0.4\n",
      "오차 행렬\n",
      "[[99 19]\n",
      " [10 51]]\n",
      "정확도: 0.8380, 정밀도: 0.7286, 재현율: 0.8361\n",
      "임곗값: 0.45\n",
      "오차 행렬\n",
      "[[103  15]\n",
      " [ 12  49]]\n",
      "정확도: 0.8492, 정밀도: 0.7656, 재현율: 0.8033\n",
      "임곗값: 0.5\n",
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869\n",
      "임곗값: 0.55\n",
      "오차 행렬\n",
      "[[109   9]\n",
      " [ 15  46]]\n",
      "정확도: 0.8659, 정밀도: 0.8364, 재현율: 0.7541\n",
      "임곗값: 0.6\n",
      "오차 행렬\n",
      "[[112   6]\n",
      " [ 16  45]]\n",
      "정확도: 0.8771, 정밀도: 0.8824, 재현율: 0.7377\n"
     ]
    }
   ],
   "source": [
    "# 테스트를 수행할 모든 임곗값을 리스트 객체로 저장. \n",
    "thresholds = [0.4, 0.45, 0.50, 0.55, 0.60]\n",
    "\n",
    "def get_eval_by_threshold(y_test , pred_proba_c1, thresholds):\n",
    "    # thresholds list객체내의 값을 차례로 iteration하면서 Evaluation 수행.\n",
    "    for custom_threshold in thresholds:\n",
    "        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1) \n",
    "        custom_predict = binarizer.transform(pred_proba_c1)\n",
    "        print('임곗값:',custom_threshold)\n",
    "        get_clf_eval(y_test , custom_predict)\n",
    "\n",
    "get_eval_by_threshold(y_test ,pred_proba[:,1].reshape(-1,1), thresholds )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임계값이 커짐에 따라 재현율은 점점 낮아지고 정밀도는 점점 높아진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**precision_recall_curve( )를 이용하여 임곗값에 따른 정밀도-재현율 값 추출**\n",
    "\n",
    "`임계값의 변화에 따른 정밀도와 재현율의 변화를 나타내는 곡선을 그리기 위해 이용하는 함수다.` 실제 target 변수 데이터와 target값이 1(positive label, titanic data의 경우 '생존' 범주를 나타낸다)이 될 예측확률을 입력하면 정밀도, 재현율, 임계값을 출력해준다.\n",
    "\n",
    "이 함수는 사이킷런의 metrics 모듈에 들어있으므로 `from sklearn.metrics import precision_recall_curve`와 같이 불러서 이용하면 된다.\n",
    "\n",
    "이 함수에 대한 상세한 설명은 [사이킷런의 설명](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html?highlight=precision_recall_curve#sklearn.metrics.precision_recall_curve)을 참조할 것."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "계속 titanic 생존자 예측 문제로 연습해보자. 앞에서 우리가 이용한 분류 방법은 로지스틱회귀였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# 레이블 값이 1일때의 예측 확률을 추출 \n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1] \n",
    "\n",
    "# 실제값 데이터 셋과 레이블 값이 1일 때의 예측 확률을 precision_recall_curve 인자로 입력 \n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_class1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반환된 분류 결정 임곗값 배열의 Shape: (143,)\n",
      "반환된 precisions 배열의 Shape: (144,)\n",
      "반환된 recalls 배열의 Shape: (144,)\n"
     ]
    }
   ],
   "source": [
    "# 반환된 분류 결정 임곗값, precision, recall 배열의 shape을 확인해보자.\n",
    "print('반환된 분류 결정 임곗값 배열의 Shape:', thresholds.shape)\n",
    "print('반환된 precisions 배열의 Shape:', precisions.shape)\n",
    "print('반환된 recalls 배열의 Shape:', recalls.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어? 왜 갯수가 한 개 차이가 나지? 임계값 하나에 정밀도와 재현율이 하나씩 나와야 맞는데? 오류가 생긴 걸까?\n",
    "\n",
    ": 의미없다.\n",
    "\n",
    "사이킷런의 설명을 보자. \n",
    "\n",
    "    The last precision and recall values are 1. and 0. respectively and do not have a corresponding threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresholds 5 sample: [0.10396312 0.10396534 0.10399023 0.10736008 0.10894927]\n",
      "precisions 5 sample: [0.38853503 0.38461538 0.38709677 0.38961039 0.38562092]\n",
      "recalls 5 sample: [1.         0.98360656 0.98360656 0.98360656 0.96721311]\n"
     ]
    }
   ],
   "source": [
    "# 임계값, 정밀도, 재현율의 처음 다섯 개 값을 보자.\n",
    "print(\"thresholds 5 sample:\", thresholds[:5])\n",
    "print(\"precisions 5 sample:\", precisions[:5])\n",
    "print(\"recalls 5 sample:\", recalls[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94891599 0.94916502 0.95070426 0.9519556  0.96515397]\n",
      "[1. 1. 1. 1. 1.]\n",
      "[0.08196721 0.06557377 0.04918033 0.03278689 0.        ]\n"
     ]
    }
   ],
   "source": [
    "# 임계값, 정밀도, 재현율의 마지막 다섯 개 값을 보자.\n",
    "print(thresholds[-5:])\n",
    "print(precisions[-5:])\n",
    "print(recalls[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런 **precision_recall_curve()** 함수는 대략 0.1 ~ 0.97 범위의 임계값에 대해 정밀도와 재현율을 계산해준다. 열 개 정도(step = 15로 두면 된다)의 임계값에 따른 정밀도, 재현율 값을 구해서 대략적인 변화를 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 추출을 위한 임계값 배열의 index 10개: [  0  15  30  45  60  75  90 105 120 135]\n",
      "샘플용 10개의 임곗값:  [0.1  0.12 0.14 0.19 0.28 0.4  0.56 0.67 0.82 0.95]\n",
      "샘플 임계값별 정밀도:  [0.389 0.44  0.466 0.539 0.647 0.729 0.836 0.949 0.958 1.   ]\n",
      "샘플 임계값별 재현율:  [1.    0.967 0.902 0.902 0.902 0.836 0.754 0.607 0.377 0.148]\n"
     ]
    }
   ],
   "source": [
    "#반환된 임계값 배열 로우가 147건이므로 샘플로 10건만 추출하되, 임곗값을 15 Step으로 추출. \n",
    "thr_index = np.arange(0, thresholds.shape[0], 15)\n",
    "print('샘플 추출을 위한 임계값 배열의 index 10개:', thr_index)\n",
    "print('샘플용 10개의 임곗값: ', np.round(thresholds[thr_index], 2))\n",
    "\n",
    "# 15 step 단위로 추출된 임계값에 따른 정밀도와 재현율 값 \n",
    "print('샘플 임계값별 정밀도: ', np.round(precisions[thr_index], 3))\n",
    "print('샘플 임계값별 재현율: ', np.round(recalls[thr_index], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`임계값이 커질수록 정밀도는 높아지고 재현율은 낮아짐을 확인할 수 있다.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 임곗값의 변경에 따른 정밀도, 재현율의 변화를 곡선으로 그려보자(x축의 tick을 교재 그림처럼 만들고 싶으면 코드 중간의 `#`을 지우고 실행). 재현율은 실선으로 정밀도는 `--`으로 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**임곗값의 변경에 따른 정밀도-재현율 변화 곡선을 그림**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "def precision_recall_curve_plot(y_test , pred_proba_c1):\n",
    "    # threshold ndarray와 이 threshold에 따른 정밀도, 재현율 ndarray 추출. \n",
    "    precisions, recalls, thresholds = precision_recall_curve( y_test, pred_proba_c1)\n",
    "    \n",
    "    # X축을 threshold값으로, Y축은 정밀도, 재현율 값으로 각각 Plot 수행. 정밀도는 점선으로 표시\n",
    "    plt.figure(figsize=(8,6))\n",
    "    threshold_boundary = thresholds.shape[0]\n",
    "    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')\n",
    "    plt.plot(thresholds, recalls[0:threshold_boundary],label='recall')\n",
    "    \n",
    "    # threshold 값 X 축의 Scale을 0.1 단위로 변경\n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
    "    \n",
    "    # x축, y축 label과 legend, 그리고 grid 설정\n",
    "    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')\n",
    "    plt.legend(); plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "precision_recall_curve_plot( y_test, lr_clf.predict_proba(X_test)[:, 1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만일 재현율과 정밀도 값이 비슷하도록 만들고 싶다면 임계값을 0.5정도로 잡으면 되겠다(교재 167쪽 결과와는 조금 다르다)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 스코어: 0.7805\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score \n",
    "f1 = f1_score(y_test , pred)\n",
    "print('F1 스코어: {0:.4f}'.format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞에서 정의했던 함수 get_clf_eval()에 fi score를 추가하고 **get_eval_by_threshold()** 함수를 실행하여 임계값이 0.4 ~ 0.65 사이의 값일 때 정확도, 정밀도, 재현율, F1 score를 구해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임곗값: 0.4\n",
      "오차 행렬\n",
      "[[99 19]\n",
      " [10 51]]\n",
      "정확도: 0.8380, 정밀도: 0.7286, 재현율: 0.8361, F1:0.7786\n",
      "임곗값: 0.45\n",
      "오차 행렬\n",
      "[[103  15]\n",
      " [ 12  49]]\n",
      "정확도: 0.8492, 정밀도: 0.7656, 재현율: 0.8033, F1:0.7840\n",
      "임곗값: 0.5\n",
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869, F1:0.7805\n",
      "임곗값: 0.55\n",
      "오차 행렬\n",
      "[[109   9]\n",
      " [ 15  46]]\n",
      "정확도: 0.8659, 정밀도: 0.8364, 재현율: 0.7541, F1:0.7931\n",
      "임곗값: 0.6\n",
      "오차 행렬\n",
      "[[112   6]\n",
      " [ 16  45]]\n",
      "정확도: 0.8771, 정밀도: 0.8824, 재현율: 0.7377, F1:0.8036\n",
      "임곗값: 0.65\n",
      "오차 행렬\n",
      "[[115   3]\n",
      " [ 22  39]]\n",
      "정확도: 0.8603, 정밀도: 0.9286, 재현율: 0.6393, F1:0.7573\n"
     ]
    }
   ],
   "source": [
    "def get_clf_eval(y_test , pred):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    # F1 스코어 추가\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # f1 score print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1:{3:.4f}'.format(accuracy, \n",
    "                                                                        precision, recall, f1))\n",
    "\n",
    "thresholds = [0.4 , 0.45 , 0.50 , 0.55 , 0.60 , 0.65]\n",
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임계값이 0.6일 때 F1 score가 가장 높은데, 그렇다고 0.6이 최선의 선택이라는 뜻은 아니다. F1은 높지만 재현율이 낮기 때문이다. `재현율을 강조해야하는 경우라면 F1이 높다고 다 좋은 것은 아니다.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 ROC Curve와 AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ROC curve (Reciever Operation Characteristic curve) : FPR(False Positive Rate, 위양성률)과 TPR(True Positive Rate, 진양성률)의 관계를 나타내는 곡선. \n",
    "\n",
    "TPR은 재현율과 같고 **FPR**은 `실제 negative 중에서 양성으로 잘못 분류된 데이터의 비율`을 의미한다.\n",
    "\n",
    "\\$ {\\rm TPR = \\frac {TP}{FN + TP}}, \\$\n",
    "\\$ {\\rm FPR = \\frac {FP}{FP + TN}} \\$\n",
    "\n",
    "의학 분야에서는 `재현율` = TPR = 진양성률을 '`민감도 `(sensitivity)'라고 부른다.  **/**  또 1 - FPR을 '`특이성`(specificity)' 또는 '`진음성률`(TNR, True Negative Rate)'이라고 부른다.\n",
    "\n",
    "    재현율 = TPR = 진양성률 = 민감도\n",
    "    특이성 = 진음성률 = TNR\n",
    "    FPR = 1 - TNR\n",
    "\n",
    "이 값들은 0과 1 사이의 값으로 나타내기도 하고 100을 곱해서 백분률로 나타내기도 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "교재 **170쪽**의 예시 곡선과 그 곡선에 대한 설명을 잘 읽어보고 아래 질문에 답해보자. \n",
    "\n",
    "    x 축의 FPR은 어떻게 0부터 100 사이의 값을 갖게 될까?\n",
    "    : 임계값이 거의 1에 가까운 경우 ~ 임계값이 0에 가까운 경우이다. 왜냐하면 임계값이 거의 1에 가까운 경우는 양성으로 분류되기란 사실 불가능하기 때문에(FP = 0) FPR은 0에 가까워진다. 또한 임계값이 거의 0에 가까운 경우 음성으로 분류 되기란 사실 불가능하기 때문에(즉, TN = 0) FPR은 100으로 가까워진다.\n",
    "    \n",
    "    왜 45도 선이 기준이 될까? \n",
    "    : 동전 던지기와 같은 엉터리 방법이기 때문이다.\n",
    "    \n",
    "    왜 ROC 곡선은 45도 기준선으로부터 멀수록 좋을까?\n",
    "    : 45도 기준선은 엉터리 방법으로 가장 성능이 나쁜 것이기 때문에 멀면 멀수록 성능이 좋은 것이다.\n",
    "\n",
    "앞에서 우리는 임계값이 커지면 양성으로 분류되기 어려워지므로 재현율은 떨어지고 정밀도는 높아진다고 공부했다. 극단적으로 임계값이 거의 1에 가깝다고 해보자. 양성으로 분류되기란 사실 불가능하므로 FPR 값은 아주 낮아질 것이다. TPR 역시 아주 낮을 것이다. ROC 곡선의 왼쪽 끝이 그런 경우다. 한편 임계값이 0에 가까워지면 거의 무조건 양성으로 분류하게 되므로 FPR은 높아진다. ROC 곡선의 오른쪽 끝이 그런 경우다. \n",
    "\n",
    "그림의 45도 선은 무엇을 나타낼까? 만일 우리가 머신러닝 분류 알고리즘과 상관없이 동전을 던져서 데이터를 랜덤하게 양성, 음성으로 분류한다고 해보자. 진짜 양성 가운데 절반은 양성, 절반은 음성으로 분류될 것이다. 진짜 음성도 마찬가지다. 이럴 때 TPR, FPR은 각각 얼마일까? 모두 0.5가 된다. \n",
    "만일 그 동전이 앞뒷면이 8:2로 나오는 동전이라면 TPR, FPR 값이 어떻게 될까? 모두 0.8이 된다. \n",
    "\n",
    "그런데 이런 분류도 괜찮을까? 당연히 가장 나쁜 분류방법이다. `즉 45도 선은 모든 분류 방법보다 성능이 떨어지는 최악의 분류방법을 이용할 때 나타나는 ROC 곡선이므로 다른 분류법의 성능을 평가하는 기준선 역할을 할 수 있다.` 따라서 ROC 곡선을 그렸을 때 45도 선에서 `멀수록 그 분류방법은 좋은 방법`이며 달리 표현하면 ROC 곡선 아래의 면적(AUC 값)이 클수록 좋은 방법이다.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런에서 ROC 곡선을 그리기 위한 FPR, TPR 값은 metrics 모듈 안에 있는 **roc_curve()** 함수를 이용해서 구할 수 있다. 이 함수는 실제 target 변수 데이터와 양성 예측 확률(predict_proba)을 입력받아 FPR, TPR 값과 임계값을 계산해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# 레이블 값이 1일때의 예측 확률을 추출 \n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1] \n",
    "\n",
    "fprs , tprs , thresholds = roc_curve(y_test, pred_proba_class1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래에서 보듯 thresholds의 첫번째 값은 max(예측확률)+1로 임의로 설정된 `부적절한 값이므로 제외시킬 필요가 있다.` (확률이기 때문에 1보다 클 수 없다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.96515397, 0.96515397, 0.91852728, 0.90889602, 0.77808684,\n",
       "       0.75101644, 0.65427068, 0.65152826, 0.6435831 , 0.63710005,\n",
       "       0.63077352, 0.63032556, 0.63030945, 0.62749053, 0.59433725,\n",
       "       0.59424326, 0.56489504, 0.54671594, 0.54615549, 0.53837583,\n",
       "       0.48878055, 0.45460491, 0.44937119, 0.44446369, 0.42908986,\n",
       "       0.39944076, 0.38026262, 0.35628953, 0.35025972, 0.34886453,\n",
       "       0.30974878, 0.30917003, 0.2406261 , 0.23471422, 0.14775389,\n",
       "       0.14775358, 0.12913759, 0.12849758, 0.12659557, 0.12541369,\n",
       "       0.1227685 , 0.12276362, 0.12270865, 0.12141462, 0.11209169,\n",
       "       0.11205751, 0.11169063, 0.11164519, 0.10894927, 0.10736008,\n",
       "       0.10396534, 0.10396312, 0.01162433])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "index 0에 해당하는 첫번째 값을 제외하고 열 개 정도만 골라서 값들의 패턴을 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 추출을 위한 임곗값 배열의 index: [ 1  6 11 16 21 26 31 36 41 46 51]\n",
      "샘플 index로 추출한 임곗값:  [0.97 0.65 0.63 0.56 0.45 0.38 0.31 0.13 0.12 0.11 0.1 ]\n",
      "샘플 임곗값별 FPR:  [0.    0.017 0.034 0.076 0.127 0.186 0.237 0.576 0.619 0.754 0.814]\n",
      "샘플 임곗값별 TPR:  [0.033 0.639 0.705 0.754 0.803 0.852 0.902 0.902 0.951 0.967 1.   ]\n"
     ]
    }
   ],
   "source": [
    "# 반환된 임곗값 배열에서 샘플로 데이터를 추출하되, 임곗값을 5 Step으로 추출. \n",
    "# thresholds[0]은 max(예측확률)+1로 임의 설정됨. 이를 제외하기 위해 np.arange는 1부터 시작\n",
    "thr_index = np.arange(1, thresholds.shape[0], 5)\n",
    "print('샘플 추출을 위한 임곗값 배열의 index:', thr_index)\n",
    "print('샘플 index로 추출한 임곗값: ', np.round(thresholds[thr_index], 2))\n",
    "\n",
    "# 5 step 단위로 추출된 임계값에 따른 FPR, TPR 값\n",
    "print('샘플 임곗값별 FPR: ', np.round(fprs[thr_index], 3))\n",
    "print('샘플 임곗값별 TPR: ', np.round(tprs[thr_index], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 결과를 보면 ROC 곡선은 `임계값이 1부터 0까지 변함`에 따라 커지는 FPR값을 x 축에 두고 TPR값을 y 축에 그린 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* AUC : Area Under Curve\n",
    "\n",
    "`ROC 곡선 아래의 면적을 뜻하며 값이 클수록 좋다`. 사이킷런에서는 metrics 모듈 안에 있는 **roc_auc_score()** 함수로 구할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC 값: 0.9024\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "pred_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
    "roc_score = roc_auc_score(y_test, pred_proba)\n",
    "print('ROC AUC 값: {0:.4f}'.format(roc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 AUC 값까지 나오도록 `get_clf_eval()` 함수를 다시 정의해서(`pred_proba`가 함수 인자로 추가되었다) 출력해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869,    F1: 0.7805, AUC:0.9024\n"
     ]
    }
   ],
   "source": [
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "pred  = lr_clf.predict(X_test)\n",
    "get_clf_eval(y_test, pred, pred_proba[:,1].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "교재 3.6절(Pima Indian Diabetes data 분석)은 생략."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# 레이블 값이 1일때의 예측 확률을 추출 \n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1] \n",
    "print('max predict_proba:', np.max(pred_proba_class1))\n",
    "\n",
    "fprs , tprs , thresholds = roc_curve(y_test, pred_proba_class1)\n",
    "print('thresholds[0]:', thresholds[0])\n",
    "# 반환된 임곗값 배열 로우가 47건이므로 샘플로 10건만 추출하되, 임곗값을 5 Step으로 추출. \n",
    "thr_index = np.arange(0, thresholds.shape[0], 5)\n",
    "print('샘플 추출을 위한 임곗값 배열의 index 10개:', thr_index)\n",
    "print('샘플용 10개의 임곗값: ', np.round(thresholds[thr_index], 2))\n",
    "\n",
    "# 5 step 단위로 추출된 임계값에 따른 FPR, TPR 값\n",
    "print('샘플 임곗값별 FPR: ', np.round(fprs[thr_index], 3))\n",
    "print('샘플 임곗값별 TPR: ', np.round(tprs[thr_index], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "### 아래는 roc_auc_score()의 인자를 잘못 입력한 것으로, 책에서 수정이 필요한 부분입니다. \n",
    "### 책에서는 roc_auc_score(y_test, pred)로 예측 타겟값을 입력하였으나 \n",
    "### roc_auc_score(y_test, y_score)로 y_score는 predict_proba()로 호출된 예측 확률 ndarray중 Positive 열에 \n",
    "#해당하는 ndarray입니다. \n",
    "\n",
    "#pred = lr_clf.predict(X_test)\n",
    "#roc_score = roc_auc_score(y_test, pred)\n",
    "\n",
    "pred_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
    "roc_score = roc_auc_score(y_test, pred_proba)\n",
    "print('ROC AUC 값: {0:.4f}'.format(roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "          F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
